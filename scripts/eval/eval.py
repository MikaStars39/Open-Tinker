#!/usr/bin/env python3
# æœ¬è„šæœ¬ä¾æ®ç”¨æˆ·éœ€æ±‚ï¼šå®ç°è¯„æµ‹æµç¨‹ï¼ˆå‚æ•°è§£æã€æ¨¡å‹åˆå¹¶ã€å¯åŠ¨vLLMã€ç”Ÿæˆã€æ‰“åˆ†ã€ç¼“å­˜/æ¢å¤ã€æ—¥å¿—ã€é˜¶æ®µåŒ–æç¤ºã€æœ€ç»ˆç»Ÿè®¡ï¼‰ã€‚
# å®ç°æ–¹æ¡ˆï¼šä½¿ç”¨argparseè§£æå¸¸è§„ä¸--vllm-*é€ä¼ å‚æ•°ï¼Œå¿…è¦æ—¶åœ¨CPUä¸Šåˆå¹¶LoRAå¹¶ä¿å­˜ï¼›åå°å¯åŠ¨æ”¯æŒæ•°æ®å¹¶è¡Œçš„vLLMæœåŠ¡å™¨ï¼Œ
# è½®è¯¢åç«¯ç”Ÿæˆå¤šæ¬¡rolloutå¹¶ç¼“å­˜åˆ°æ–‡ä»¶ï¼Œéšåè°ƒç”¨score_responseæ±‡æ€»ä¸ºresult.jsonlï¼Œæœ€åæ–°å¢ä¸€ä¸ªç»Ÿè®¡é˜¶æ®µè¾“å‡ºavg@k/pass@kï¼Œ
# åŒæ—¶è®°å½•æ—¥å¿—å¹¶å°†stdout/stderrå†™å…¥latest_run.logï¼›é€šè¿‡é˜¶æ®µåŒ–æ—¥å¿—æ ‡æ˜ç¬¬å‡ é˜¶æ®µçš„å¼€å§‹/ç»“æŸï¼ˆå«emojiï¼‰ã€‚

import argparse
import atexit
import json
import logging
import os
import signal
import subprocess
import sys
import threading
import time
import urllib.error
import urllib.request
from pathlib import Path
from typing import Any, Dict, Iterable, List, Tuple
import math

from datasets import load_dataset
from peft import PeftModel
from transformers import AutoModelForCausalLM, AutoTokenizer
from transformers.utils import get_torch_dtype


class StreamToLogger:
    """Redirect stdout/stderråˆ°loggerï¼Œç¡®ä¿è¾“å‡ºè¢«æ–‡ä»¶ä¸æ§åˆ¶å°åŒæ—¶è®°å½•ã€‚"""

    def __init__(self, logger: logging.Logger, level: int) -> None:
        self.logger = logger
        self.level = level
        self._buffer = ""

    def write(self, buffer: str) -> None:
        self._buffer += buffer
        while "\n" in self._buffer:
            line, self._buffer = self._buffer.split("\n", 1)
            self.logger.log(self.level, line)

    def flush(self) -> None:
        if self._buffer:
            self.logger.log(self.level, self._buffer)
            self._buffer = ""


def setup_logging(result_dir: Path) -> logging.Logger:
    result_dir.mkdir(parents=True, exist_ok=True)
    log_path = result_dir / "latest_run.log"

    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)

    logging.root.setLevel(logging.INFO)
    formatter = logging.Formatter("%(asctime)s | %(levelname)s | %(message)s")
    file_handler = logging.FileHandler(log_path, mode="w", encoding="utf-8")
    file_handler.setFormatter(formatter)
    console_handler = logging.StreamHandler(sys.__stdout__)
    console_handler.setFormatter(formatter)
    logging.root.addHandler(file_handler)
    logging.root.addHandler(console_handler)

    stdout_logger = logging.getLogger("stdout")
    stdout_logger.setLevel(logging.INFO)
    stdout_logger.propagate = True
    stderr_logger = logging.getLogger("stderr")
    stderr_logger.setLevel(logging.ERROR)
    stderr_logger.propagate = True
    sys.stdout = StreamToLogger(stdout_logger, logging.INFO)
    sys.stderr = StreamToLogger(stderr_logger, logging.ERROR)

    return logging.getLogger("eval_all")


class StageContext:
    """é˜¶æ®µåŒ–æ—¥å¿—ä¸Šä¸‹æ–‡ï¼Œæ ‡è®°å¼€å§‹/ç»“æŸå’Œå¤±è´¥åœºæ™¯ã€‚"""

    def __init__(
        self,
        logger: logging.Logger,
        stage_id: int,
        name: str,
        emoji_start: str = "ğŸš€",
        emoji_end: str = "ğŸ",
        emoji_fail: str = "ğŸ’¥",
    ) -> None:
        self.logger = logger
        self.stage_id = stage_id
        self.name = name
        self.emoji_start = emoji_start
        self.emoji_end = emoji_end
        self.emoji_fail = emoji_fail

    def __enter__(self) -> "StageContext":
        self.logger.info("%s ç¬¬%dé˜¶æ®µå¼€å§‹ï¼š%s", self.emoji_start, self.stage_id, self.name)
        return self

    def __exit__(self, exc_type, exc, tb) -> None:  # noqa: ANN001
        if exc_type is None:
            self.logger.info("%s ç¬¬%dé˜¶æ®µç»“æŸï¼š%s", self.emoji_end, self.stage_id, self.name)
        else:
            self.logger.error("%s ç¬¬%dé˜¶æ®µå¤±è´¥ï¼š%sï¼Œé”™è¯¯ï¼š%s", self.emoji_fail, self.stage_id, self.name, exc)


def parse_args() -> Tuple[argparse.Namespace, List[str], List[str]]:
    parser = argparse.ArgumentParser(description="è¯„æµ‹å…¥å£è„šæœ¬ï¼Œæ”¯æŒæ¨¡å‹åˆå¹¶ã€vLLMå¯åŠ¨ä¸å¤šæ•°æ®é›†è¯„æµ‹ã€‚")
    parser.add_argument("--result-dir", required=True, help="ä¸­é—´è¿‡ç¨‹ä¸ç»“æœè¾“å‡ºç›®å½•ã€‚")
    parser.add_argument("--model", required=True, help="åŸºç¡€æ¨¡å‹åç§°æˆ–è·¯å¾„ã€‚")
    parser.add_argument("--adapter", default="", help="LoRA/PEFT adapterè·¯å¾„ï¼Œç•™ç©ºè¡¨ç¤ºä¸åˆå¹¶ã€‚")
    parser.add_argument("--dataset", default="HuggingFaceH4/aime_2024", help="è¦è¯„æµ‹çš„æ•°æ®é›†ï¼Œè‹±æ–‡é€—å·åˆ†éš”ã€‚")
    parser.add_argument("--rollout-n", type=int, default=1, help="æ¯ä¸ªsampleç”Ÿæˆå¤šå°‘æ¬¡rolloutã€‚")
    parser.add_argument("--serve-port", type=int, default=8000, help="ç¬¬ä¸€ä¸ªvLLMåç«¯ç«¯å£å·ã€‚")
    parser.add_argument("--dp-size", type=int, default=1, help="æ•°æ®å¹¶è¡Œåç«¯æ•°é‡ï¼ˆå¯åŠ¨å¤šä¸ªvLLMï¼‰ã€‚")
    parser.add_argument("--tp-size", type=int, default=1, help="ä¼ ç»™vLLMçš„å¼ é‡å¹¶è¡Œå¤§å°ã€‚")
    parser.add_argument("--temperature", type=float, default=1.0, help="ç”Ÿæˆæ¸©åº¦ã€‚")
    parser.add_argument("--top-p", type=float, default=1.0, help="ç”Ÿæˆtop-pã€‚")
    parser.add_argument("--max-new-tokens", type=int, default=131072, help="ç”Ÿæˆé•¿åº¦ã€‚")
    parser.add_argument("--dtype", default="auto", help="æ¨¡å‹dtypeï¼Œç”¨äºåˆå¹¶ç¯èŠ‚ã€‚")
    parser.add_argument("--trust-remote-code", action="store_true", help="æ˜¯å¦ä¿¡ä»»è¿œç¨‹ä»£ç ã€‚")
    parser.add_argument("--served-model-name", default="eval-model", help="vLLMå¯¹å¤–æš´éœ²çš„æ¨¡å‹åã€‚")
    parser.add_argument("--api-key", default="dummy", help="OpenAIå…¼å®¹æ¥å£çš„API Keyã€‚")
    parser.add_argument("--request-timeout", type=float, default=600.0, help="è¯·æ±‚å•æ¬¡è¶…æ—¶æ—¶é—´ã€‚")
    parser.add_argument("--max-samples", type=int, default=None, help="è°ƒè¯•ç”¨ï¼Œé™åˆ¶è¯„æµ‹æ ·æœ¬æ•°é‡ã€‚")

    args, unknown = parser.parse_known_args()
    vllm_args, leftover = extract_vllm_args(unknown)
    return args, vllm_args, leftover


def extract_vllm_args(unknown: List[str]) -> Tuple[List[str], List[str]]:
    vllm_args: List[str] = []
    leftover: List[str] = []
    idx = 0
    while idx < len(unknown):
        token = unknown[idx]
        if token.startswith("--vllm-"):
            stripped = "--" + token[len("--vllm-"):]
            if "=" in token:
                _, value = token.split("=", 1)
                vllm_args.extend([stripped, value])
            elif idx + 1 < len(unknown) and not unknown[idx + 1].startswith("-"):
                vllm_args.extend([stripped, unknown[idx + 1]])
                idx += 1
            else:
                vllm_args.append(stripped)
        else:
            leftover.append(token)
        idx += 1
    return vllm_args, leftover


def prepare_prompt(sample: Dict[str, Any]) -> str:
    """æ ¹æ®sampleæ„å»ºæ¨¡å‹è¾“å…¥promptï¼Œå¯æŒ‰éœ€ä¿®æ”¹å¢å¼ºã€‚"""
    if isinstance(sample, dict):
        if "prompt" in sample:
            return str(sample["prompt"])
        if "instruction" in sample and "input" in sample:
            return f"{sample['instruction']}\n{sample['input']}"
        if "instruction" in sample:
            return str(sample["instruction"])
        if "question" in sample:
            return str(sample["question"])
        if "text" in sample:
            return str(sample["text"])
    return str(sample)


def score_response(prompt: str, response: str, sample: Dict[str, Any]) -> float:
    """ç®€å•å ä½è¯„åˆ†ï¼šè‹¥sampleåŒ…å«answer/labelä¸”å‡ºç°åœ¨responseåˆ™è®°1ï¼Œå¦åˆ™0ã€‚"""
    answer = None
    if isinstance(sample, dict):
        answer = sample.get("answer") or sample.get("label")
    if answer is None:
        return 0.0
    return float(str(answer) in response)


def merge_model_if_needed(args: argparse.Namespace, result_dir: Path, logger: logging.Logger) -> Path:
    if not args.adapter:
        logger.info("æœªæä¾›adapterï¼Œç›´æ¥ä½¿ç”¨åŸºç¡€æ¨¡å‹ï¼š%s", args.model)
        return Path(args.model)

    output_dir = result_dir / "model"
    if output_dir.exists() and any(output_dir.iterdir()):
        logger.info("æ£€æµ‹åˆ°å·²å­˜åœ¨çš„åˆå¹¶æ¨¡å‹ç›®å½•ï¼Œç›´æ¥å¤ç”¨ï¼š%s", output_dir)
        return output_dir

    torch_dtype = get_torch_dtype(args.dtype)
    logger.info("åŠ è½½åŸºç¡€æ¨¡å‹ï¼š%s", args.model)
    model = AutoModelForCausalLM.from_pretrained(
        args.model,
        torch_dtype=torch_dtype,
        device_map="cpu",
        trust_remote_code=args.trust_remote_code,
    )
    logger.info("åŠ è½½åˆ†è¯å™¨ï¼š%s", args.model)
    tokenizer = AutoTokenizer.from_pretrained(
        args.model,
        trust_remote_code=args.trust_remote_code,
    )
    logger.info("åŠ è½½LoRA/PEFT adapterï¼š%s", args.adapter)
    model = PeftModel.from_pretrained(model, args.adapter)
    logger.info("æ‰§è¡Œmerge_and_unloadï¼Œå°†LoRAæƒé‡å†™å…¥åŸºç¡€æ¨¡å‹ã€‚")
    model = model.merge_and_unload()

    logger.info("ä¿å­˜åˆå¹¶æ¨¡å‹è‡³ï¼š%s", output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    model.save_pretrained(output_dir)
    tokenizer.save_pretrained(output_dir)
    return output_dir


def build_vllm_command(model_path: Path, port: int, args: argparse.Namespace, vllm_args: List[str]) -> List[str]:
    cmd = [
        sys.executable,
        "-m",
        "vllm.entrypoints.openai.api_server",
        "--model",
        str(model_path),
        "--served-model-name",
        args.served_model_name,
        "--port",
        str(port),
        "--tensor-parallel-size",
        str(args.tp_size),
    ]
    if args.trust_remote_code:
        cmd.append("--trust-remote-code")
    cmd.extend(vllm_args)
    return cmd


def pipe_to_logger(stream: Iterable[str], logger: logging.Logger, level: int, prefix: str) -> None:
    for line in stream:
        logger.log(level, "%s%s", prefix, line.rstrip("\n"))


def start_vllm_processes(
    model_path: Path, args: argparse.Namespace, vllm_args: List[str], logger: logging.Logger
) -> Tuple[List[subprocess.Popen], List[int]]:
    ports: List[int] = []
    processes: List[subprocess.Popen] = []
    env = os.environ.copy()

    for rank in range(max(1, args.dp_size)):
        port = args.serve_port + rank
        cmd = build_vllm_command(model_path, port, args, vllm_args)
        logger.info("å¯åŠ¨vLLMåç«¯[%d/%d]ï¼Œç«¯å£%dï¼Œå‘½ä»¤ï¼š%s", rank + 1, args.dp_size, port, " ".join(cmd))
        proc = subprocess.Popen(
            cmd,
            env=env,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            bufsize=1,
            preexec_fn=os.setsid,
        )
        processes.append(proc)
        ports.append(port)
        if proc.stdout:
            threading.Thread(
                target=pipe_to_logger,
                args=(proc.stdout, logger, logging.INFO, f"[vllm:{port}] "),
                daemon=True,
            ).start()
        if proc.stderr:
            threading.Thread(
                target=pipe_to_logger,
                args=(proc.stderr, logger, logging.ERROR, f"[vllm:{port}] "),
                daemon=True,
            ).start()
    return processes, ports


def stop_vllm_processes(processes: List[subprocess.Popen], logger: logging.Logger) -> None:
    for proc in processes:
        if proc.poll() is None:
            try:
                logger.info("å°è¯•ç»ˆæ­¢vLLMè¿›ç¨‹(pid=%d)ã€‚", proc.pid)
                os.killpg(os.getpgid(proc.pid), signal.SIGTERM)
            except Exception as exc:  # noqa: BLE001
                logger.warning("ç»ˆæ­¢è¿›ç¨‹(pid=%d)æ—¶å‘ç”Ÿå¼‚å¸¸ï¼š%s", proc.pid, exc)
    for proc in processes:
        if proc.poll() is None:
            try:
                proc.wait(timeout=10)
            except Exception:  # noqa: BLE001
                try:
                    os.killpg(os.getpgid(proc.pid), signal.SIGKILL)
                except Exception:
                    pass


def wait_for_vllm_ready(port: int, process: subprocess.Popen, timeout: float, logger: logging.Logger) -> bool:
    deadline = time.time() + timeout
    url = f"http://127.0.0.1:{port}/health"
    while time.time() < deadline:
        if process.poll() is not None:
            logger.error("vLLMè¿›ç¨‹(pid=%d)æå‰é€€å‡ºã€‚", process.pid)
            return False
        try:
            with urllib.request.urlopen(url, timeout=5) as resp:
                if resp.status == 200:
                    logger.info("ç«¯å£%dçš„vLLMå·²å°±ç»ªã€‚", port)
                    return True
        except Exception:
            time.sleep(2)
    logger.error("ç­‰å¾…ç«¯å£%dçš„vLLMè¶…æ—¶ã€‚", port)
    return False


def load_dataset_by_name(name: str, split: str):
    if ":" in name:
        path, subset = name.split(":", 1)
        return load_dataset(path, subset, split=split)
    return load_dataset(name, split=split)


def generate_with_vllm(prompt: str, port: int, args: argparse.Namespace) -> str:
    url = f"http://127.0.0.1:{port}/v1/chat/completions"
    payload = {
        "model": args.served_model_name,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": args.temperature,
        "top_p": args.top_p,
        "max_tokens": args.max_new_tokens,
        "n": 1,
    }
    data = json.dumps(payload).encode("utf-8")
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {args.api_key}",
    }
    request = urllib.request.Request(url, data=data, headers=headers, method="POST")
    try:
        with urllib.request.urlopen(request, timeout=args.request_timeout) as response:
            body = response.read().decode("utf-8")
            content = json.loads(body)
    except urllib.error.HTTPError as exc:
        raise RuntimeError(f"vLLMè¿”å›HTTPé”™è¯¯: {exc}") from exc
    except urllib.error.URLError as exc:
        raise RuntimeError(f"vLLMè¿æ¥å¤±è´¥: {exc}") from exc

    try:
        return content["choices"][0]["message"]["content"]
    except Exception as exc:  # noqa: BLE001
        raise RuntimeError(f"è§£ævLLMå“åº”å¤±è´¥: {content}") from exc


def save_text(path: Path, text: str) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(text, encoding="utf-8")


def evaluate_dataset(
    dataset_name: str,
    args: argparse.Namespace,
    ports: List[int],
    logger: logging.Logger,
) -> List[Dict[str, Any]]:
    dataset_dir = Path(args.result_dir) / dataset_name
    outputs_dir = dataset_dir / "outputs"
    result_file = dataset_dir / "result.jsonl"

    if result_file.exists():
        logger.warning("æ£€æµ‹åˆ°å·²å­˜åœ¨çš„ç»“æœæ–‡ä»¶ï¼Œè·³è¿‡é‡æ–°è¯„æµ‹æ•°æ®é›† %s : %s", dataset_name, result_file)
        try:
            with result_file.open("r", encoding="utf-8") as f:
                return [json.loads(line) for line in f if line.strip()]
        except Exception as exc:  # noqa: BLE001
            logger.error("è¯»å–å·²æœ‰ç»“æœå¤±è´¥ï¼Œå°†é‡æ–°è¯„æµ‹ã€‚é”™è¯¯ï¼š%s", exc)

    # ç”¨æˆ·éœ€æ±‚ï¼šåˆ é™¤ --dataset-split å‚æ•°ï¼Œé»˜è®¤ä½¿ç”¨ testï¼Œä¸å­˜åœ¨åˆ™é€šè¿‡ logger.warning æŠ¥é”™å¹¶å›é€€åˆ° trainã€‚
    split = "test"
    try:
        logger.info("åŠ è½½æ•°æ®é›† %s split=%s", dataset_name, split)
        ds = load_dataset_by_name(dataset_name, split)
    except ValueError as exc:
        logger.warning(
            "æ•°æ®é›† %s ä¸å­˜åœ¨ split=%sï¼Œå°†å›é€€åˆ° split=trainã€‚åŸå§‹é”™è¯¯ï¼š%s",
            dataset_name,
            split,
            exc,
        )
        split = "train"
        logger.info("åŠ è½½æ•°æ®é›† %s split=%s", dataset_name, split)
        ds = load_dataset_by_name(dataset_name, split)
    records: List[Dict[str, Any]] = []
    ports_cycle = len(ports)
    rollout_counter = 0

    for idx, sample in enumerate(ds):
        if args.max_samples is not None and idx >= args.max_samples:
            logger.info("å‘½ä¸­max_samples=%dï¼Œæå‰ç»“æŸã€‚", args.max_samples)
            break
        prompt = prepare_prompt(sample)
        problem_dir = outputs_dir / f"{idx:06d}"
        for rollout_id in range(args.rollout_n):
            output_path = problem_dir / f"rollout_{rollout_id:03d}.txt"
            if output_path.exists() and output_path.stat().st_size > 0:
                response = output_path.read_text(encoding="utf-8")
                logger.info("å¤ç”¨ç¼“å­˜ç»“æœï¼š%s", output_path)
            else:
                port = ports[rollout_counter % ports_cycle]
                rollout_counter += 1
                logger.info("å‘ç«¯å£%dè¯·æ±‚ç”Ÿæˆï¼Œproblem=%06d rollout=%03d", port, idx, rollout_id)
                response = generate_with_vllm(prompt, port, args)
                save_text(output_path, response)
            score = score_response(prompt, response, sample)
            records.append(
                {
                    "problem_id": idx,
                    "rollout_id": rollout_id,
                    "prompt": prompt,
                    "response": response,
                    "score": score,
                }
            )

    result_file.parent.mkdir(parents=True, exist_ok=True)
    with result_file.open("w", encoding="utf-8") as f:
        for record in records:
            f.write(json.dumps(record, ensure_ascii=False) + "\n")
    logger.info("æ•°æ®é›† %s è¯„æµ‹å®Œæˆï¼Œç»“æœå†™å…¥ %s", dataset_name, result_file)
    return records


def compute_pass_at_k(num_samples: int, num_correct: int, k: int) -> float:
    if num_correct == 0:
        return 0.0
    if num_samples <= k:
        return 1.0 if num_correct > 0 else 0.0
    return 1 - (math.comb(num_samples - num_correct, k) / math.comb(num_samples, k))


def compute_metrics(records: List[Dict[str, Any]], rollout_n: int) -> Dict[str, Dict[int, float]]:
    by_problem: Dict[int, List[float]] = {}
    for rec in records:
        by_problem.setdefault(int(rec["problem_id"]), []).append(float(rec["score"]))

    avg_at_k: Dict[int, float] = {}
    pass_at_k: Dict[int, float] = {}

    for k in range(1, rollout_n + 1):
        avg_scores = []
        pass_scores = []
        for scores in by_problem.values():
            sorted_scores = sorted(scores, reverse=True)
            topk = sorted_scores[:k]
            if topk:
                avg_scores.append(sum(topk) / len(topk))
            c = sum(1 for s in scores if s > 0)
            pass_scores.append(compute_pass_at_k(len(scores), c, k))

        avg_at_k[k] = sum(avg_scores) / len(avg_scores) if avg_scores else 0.0
        pass_at_k[k] = sum(pass_scores) / len(pass_scores) if pass_scores else 0.0

    return {"avg_at_k": avg_at_k, "pass_at_k": pass_at_k}


def main() -> None:
    args, vllm_args, leftover = parse_args()
    logger = setup_logging(Path(args.result_dir))
    if leftover:
        logger.warning("æ£€æµ‹åˆ°æ— æ³•è¯†åˆ«çš„å‚æ•°ï¼ˆå°†è¢«å¿½ç•¥ï¼‰ï¼š%s", leftover)

    with StageContext(logger, 1, "å‡†å¤‡æ¨¡å‹/åˆå¹¶LoRA"):
        model_path = merge_model_if_needed(args, Path(args.result_dir), logger)

    with StageContext(logger, 2, "å¯åŠ¨vLLMåç«¯"):
        processes, ports = start_vllm_processes(model_path, args, vllm_args, logger)
        atexit.register(stop_vllm_processes, processes, logger)

        def handle_signal(signum, frame):  # noqa: ANN001
            logger.warning("æ”¶åˆ°ä¿¡å·%dï¼Œå‡†å¤‡æ¸…ç†åé€€å‡ºã€‚", signum)
            stop_vllm_processes(processes, logger)
            sys.exit(1)

        signal.signal(signal.SIGINT, handle_signal)
        signal.signal(signal.SIGTERM, handle_signal)

        for proc, port in zip(processes, ports):
            if not wait_for_vllm_ready(port, proc, timeout=300, logger=logger):
                stop_vllm_processes(processes, logger)
                sys.exit(1)

    all_records: Dict[str, List[Dict[str, Any]]] = {}
    datasets_to_run = [item.strip() for item in args.dataset.split(",") if item.strip()]
    with StageContext(logger, 3, "æ•°æ®é›†è¯„æµ‹ä¸ç¼“å­˜/ç”Ÿæˆ"):
        for name in datasets_to_run:
            logger.info("ğŸ§ª å¼€å§‹è¯„æµ‹æ•°æ®é›†ï¼š%s", name)
            records = evaluate_dataset(name, args, ports, logger)
            all_records[name] = records
            logger.info("âœ… å®Œæˆè¯„æµ‹æ•°æ®é›†ï¼š%s", name)

    with StageContext(logger, 4, "ç»Ÿè®¡é˜¶æ®µï¼šè®¡ç®—avg@kä¸pass@k"):
        overall_records: List[Dict[str, Any]] = []
        for name, records in all_records.items():
            overall_records.extend(records)
            metrics = compute_metrics(records, args.rollout_n)
            logger.info("ğŸ“Š æ•°æ®é›†%s avg@k: %s", name, metrics["avg_at_k"])
            logger.info("ğŸ“ˆ æ•°æ®é›†%s pass@k: %s", name, metrics["pass_at_k"])

        overall_metrics = compute_metrics(overall_records, args.rollout_n) if overall_records else None
        if overall_metrics:
            logger.info("ğŸŒ å…¨éƒ¨æ•°æ®é›†åˆå¹¶ avg@k: %s", overall_metrics["avg_at_k"])
            logger.info("ğŸŒŸ å…¨éƒ¨æ•°æ®é›†åˆå¹¶ pass@k: %s", overall_metrics["pass_at_k"])
        else:
            logger.warning("æœªè·å–åˆ°ä»»ä½•è®°å½•ï¼Œè·³è¿‡å…¨å±€ç»Ÿè®¡ã€‚")

    stop_vllm_processes(processes, logger)
    logger.info("å…¨éƒ¨è¯„æµ‹æµç¨‹å®Œæˆã€‚")


if __name__ == "__main__":
    main()
